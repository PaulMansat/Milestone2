JAVA.LANG => TYPE 6 ? 

Container: container_e02_1580812675067_4186_01_000003 on iccluster055.iccluster.epfl.ch_45454_1586013333980
LogAggregationType: AGGREGATED
===========================================================================================================
LogType:stderr
LogLastModifiedTime:Sat Apr 04 17:15:34 +0200 2020
LogLength:12631
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/hdata/sdc/hadoop/yarn/local/filecache/10/spark2-hdp-yarn-archive.tar.gz/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.0.1.0-187/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/04/04 17:13:38 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 7319@iccluster055
20/04/04 17:13:38 INFO SignalUtils: Registered signal handler for TERM
20/04/04 17:13:38 INFO SignalUtils: Registered signal handler for HUP
20/04/04 17:13:38 INFO SignalUtils: Registered signal handler for INT
20/04/04 17:13:39 INFO SecurityManager: Changing view acls to: yarn,sahnoun
20/04/04 17:13:39 INFO SecurityManager: Changing modify acls to: yarn,sahnoun
20/04/04 17:13:39 INFO SecurityManager: Changing view acls groups to: 
20/04/04 17:13:39 INFO SecurityManager: Changing modify acls groups to: 
20/04/04 17:13:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, sahnoun); groups with view permissions: Set(); users  with modify permissions: Set(yarn, sahnoun); groups with modify permissions: Set()
20/04/04 17:13:39 INFO TransportClientFactory: Successfully created connection to iccluster056.iccluster.epfl.ch/10.90.39.7:40063 after 99 ms (0 ms spent in bootstraps)
20/04/04 17:13:39 INFO SecurityManager: Changing view acls to: yarn,sahnoun
20/04/04 17:13:39 INFO SecurityManager: Changing modify acls to: yarn,sahnoun
20/04/04 17:13:39 INFO SecurityManager: Changing view acls groups to: 
20/04/04 17:13:39 INFO SecurityManager: Changing modify acls groups to: 
20/04/04 17:13:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, sahnoun); groups with view permissions: Set(); users  with modify permissions: Set(yarn, sahnoun); groups with modify permissions: Set()
20/04/04 17:13:39 INFO TransportClientFactory: Successfully created connection to iccluster056.iccluster.epfl.ch/10.90.39.7:40063 after 2 ms (0 ms spent in bootstraps)
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-d7becaf6-b36c-45d7-a7ee-e1cf5133c2c8
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sdb/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-aa3b228a-dcf6-4a11-b616-cbefb737b635
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sdc/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-36df5814-a926-4693-bf0e-d84ccb892856
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sdd/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-7b42f0e4-e174-4186-9f44-e798952de5db
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sde/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-00026b59-966b-4b74-9b91-c05121c8e4ae
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sdf/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-f09444fb-893a-4492-aae3-1ac25bccab41
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sdg/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-8640ffb6-2692-4d2e-9e91-b62264eeab6b
20/04/04 17:13:40 INFO MemoryStore: MemoryStore started with capacity 408.9 MB
20/04/04 17:13:40 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@iccluster056.iccluster.epfl.ch:40063
20/04/04 17:13:40 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/04 17:13:40 INFO Executor: Starting executor ID 2 on host iccluster055.iccluster.epfl.ch
20/04/04 17:13:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46685.
20/04/04 17:13:40 INFO NettyBlockTransferService: Server created on iccluster055.iccluster.epfl.ch:46685
20/04/04 17:13:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/04 17:13:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(2, iccluster055.iccluster.epfl.ch, 46685, None)
20/04/04 17:13:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(2, iccluster055.iccluster.epfl.ch, 46685, None)
20/04/04 17:13:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(2, iccluster055.iccluster.epfl.ch, 46685, None)
20/04/04 17:13:44 INFO CoarseGrainedExecutorBackend: Got assigned task 1
20/04/04 17:13:44 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
20/04/04 17:13:44 INFO TorrentBroadcast: Started reading broadcast variable 1
20/04/04 17:13:44 INFO TransportClientFactory: Successfully created connection to iccluster056.iccluster.epfl.ch/10.90.39.7:45435 after 2 ms (0 ms spent in bootstraps)
20/04/04 17:13:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.8 KB, free 408.9 MB)
20/04/04 17:13:44 INFO TorrentBroadcast: Reading broadcast variable 1 took 117 ms
20/04/04 17:13:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.2 KB, free 408.9 MB)
20/04/04 17:13:44 INFO HadoopRDD: Input split: hdfs://iccluster040.iccluster.epfl.ch:8020/cs449/data1_large.csv:53999515+53999516
20/04/04 17:13:44 INFO TorrentBroadcast: Started reading broadcast variable 0
20/04/04 17:13:44 INFO TransportClientFactory: Successfully created connection to iccluster063.iccluster.epfl.ch/10.90.39.14:40402 after 1 ms (0 ms spent in bootstraps)
20/04/04 17:13:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 43.7 KB, free 408.8 MB)
20/04/04 17:13:44 INFO TorrentBroadcast: Reading broadcast variable 0 took 49 ms
20/04/04 17:13:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 673.8 KB, free 408.2 MB)
20/04/04 17:13:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1038 bytes result sent to driver
20/04/04 17:13:52 INFO CoarseGrainedExecutorBackend: Got assigned task 3
20/04/04 17:13:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
20/04/04 17:13:52 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
20/04/04 17:13:52 INFO TorrentBroadcast: Started reading broadcast variable 2
20/04/04 17:13:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.2 KB, free 408.2 MB)
20/04/04 17:13:52 INFO TorrentBroadcast: Reading broadcast variable 2 took 14 ms
20/04/04 17:13:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.4 KB, free 408.2 MB)
20/04/04 17:13:52 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/04 17:13:52 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@iccluster056.iccluster.epfl.ch:40063)
20/04/04 17:13:52 INFO MapOutputTrackerWorker: Got the output locations
20/04/04 17:13:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
20/04/04 17:13:52 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 11 ms
20/04/04 17:15:31 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
20/04/04 17:15:31 INFO DiskBlockManager: Shutdown hook called
20/04/04 17:15:31 ERROR Executor: Exception in task 1.0 in stage 1.0 (TID 3)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.Integer.valueOf(Integer.java:832)
	at scala.runtime.BoxesRunTime.boxToInteger(BoxesRunTime.java:65)
	at App3$$anonfun$4$$anonfun$apply$2.apply(App3.scala:23)
	at App3$$anonfun$4$$anonfun$apply$2.apply(App3.scala:23)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.immutable.Range.foreach(Range.scala:160)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at App3$$anonfun$4.apply(App3.scala:23)
	at App3$$anonfun$4.apply(App3.scala:23)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
20/04/04 17:15:31 INFO Executor: Not reporting error to driver during JVM shutdown.
20/04/04 17:15:31 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 3,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.Integer.valueOf(Integer.java:832)
	at scala.runtime.BoxesRunTime.boxToInteger(BoxesRunTime.java:65)
	at App3$$anonfun$4$$anonfun$apply$2.apply(App3.scala:23)
	at App3$$anonfun$4$$anonfun$apply$2.apply(App3.scala:23)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.immutable.Range.foreach(Range.scala:160)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at App3$$anonfun$4.apply(App3.scala:23)
	at App3$$anonfun$4.apply(App3.scala:23)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
20/04/04 17:15:31 INFO ShutdownHookManager: Shutdown hook called

End of LogType:stderr
***********************************************************************
Container: container_e02_1580812675067_4186_01_000001 on iccluster056.iccluster.epfl.ch_45454_1586013334456
LogAggregationType: AGGREGATED
===========================================================================================================
LogType:stderr
LogLastModifiedTime:Sat Apr 04 17:15:34 +0200 2020
LogLength:37526
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/hdata/sdg/hadoop/yarn/local/filecache/12/spark2-hdp-yarn-archive.tar.gz/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.0.1.0-187/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/04/04 17:13:34 INFO SignalUtils: Registered signal handler for TERM
20/04/04 17:13:34 INFO SignalUtils: Registered signal handler for HUP
20/04/04 17:13:34 INFO SignalUtils: Registered signal handler for INT
20/04/04 17:13:34 INFO SecurityManager: Changing view acls to: yarn,sahnoun
20/04/04 17:13:34 INFO SecurityManager: Changing modify acls to: yarn,sahnoun
20/04/04 17:13:34 INFO SecurityManager: Changing view acls groups to: 
20/04/04 17:13:34 INFO SecurityManager: Changing modify acls groups to: 
20/04/04 17:13:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, sahnoun); groups with view permissions: Set(); users  with modify permissions: Set(yarn, sahnoun); groups with modify permissions: Set()
20/04/04 17:13:34 INFO ApplicationMaster: Preparing Local resources
20/04/04 17:13:35 INFO ApplicationMaster: ApplicationAttemptId: appattempt_1580812675067_4186_000001
20/04/04 17:13:35 INFO ApplicationMaster: Starting the user application in a separate Thread
20/04/04 17:13:35 INFO ApplicationMaster: Waiting for spark context initialization...
20/04/04 17:13:35 INFO SparkContext: Running Spark version 2.3.1.3.0.1.0-187
20/04/04 17:13:35 INFO SparkContext: Submitted application: M2 App3
20/04/04 17:13:35 INFO SecurityManager: Changing view acls to: yarn,sahnoun
20/04/04 17:13:35 INFO SecurityManager: Changing modify acls to: yarn,sahnoun
20/04/04 17:13:35 INFO SecurityManager: Changing view acls groups to: 
20/04/04 17:13:35 INFO SecurityManager: Changing modify acls groups to: 
20/04/04 17:13:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, sahnoun); groups with view permissions: Set(); users  with modify permissions: Set(yarn, sahnoun); groups with modify permissions: Set()
20/04/04 17:13:36 INFO Utils: Successfully started service 'sparkDriver' on port 40063.
20/04/04 17:13:36 INFO SparkEnv: Registering MapOutputTracker
20/04/04 17:13:36 INFO SparkEnv: Registering BlockManagerMaster
20/04/04 17:13:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/04/04 17:13:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/04/04 17:13:36 INFO DiskBlockManager: Created local directory at /hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-461305a5-6e4b-489f-a999-a624ec8c9e2c
20/04/04 17:13:36 INFO DiskBlockManager: Created local directory at /hdata/sdb/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-368057b5-239e-48dc-9633-d18fdd235b26
20/04/04 17:13:36 INFO DiskBlockManager: Created local directory at /hdata/sdc/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-6d14e839-cc63-4c02-95bd-3373b697d628
20/04/04 17:13:36 INFO DiskBlockManager: Created local directory at /hdata/sdd/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-a52d22f0-0545-4277-9827-41d623d5d93e
20/04/04 17:13:36 INFO DiskBlockManager: Created local directory at /hdata/sde/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-9eb2dd89-ed46-4081-a0b8-26c19a69962e
20/04/04 17:13:36 INFO DiskBlockManager: Created local directory at /hdata/sdf/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-bc4c5f03-9de4-445f-85d1-febd58c169e1
20/04/04 17:13:36 INFO DiskBlockManager: Created local directory at /hdata/sdg/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-d2d196cd-813b-4752-b25d-d9efd389a40b
20/04/04 17:13:36 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
20/04/04 17:13:36 INFO SparkEnv: Registering OutputCommitCoordinator
20/04/04 17:13:36 INFO log: Logging initialized @2800ms
20/04/04 17:13:36 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/04/04 17:13:36 INFO Server: jetty-9.3.z-SNAPSHOT, build timestamp: 2018-06-05T19:11:56+02:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
20/04/04 17:13:36 INFO Server: Started @2879ms
20/04/04 17:13:36 INFO AbstractConnector: Started ServerConnector@3a999908{HTTP/1.1,[http/1.1]}{0.0.0.0:40378}
20/04/04 17:13:36 INFO Utils: Successfully started service 'SparkUI' on port 40378.
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@30802dbc{/jobs,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5c951caa{/jobs/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4c78e4a7{/jobs/job,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@40e2cee{/jobs/job/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@fd8bd14{/stages,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@26092bc8{/stages/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@65393c6{/stages/stage,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@568dbe4b{/stages/stage/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4c5adaff{/stages/pool,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@422eef8c{/stages/pool/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@57a099e2{/storage,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6ce40abb{/storage/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@76f3a8fa{/storage/rdd,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@43946b27{/storage/rdd/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@10a8953e{/environment,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5c55e442{/environment/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@378a334a{/executors,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5727bbcf{/executors/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3f2c570{/executors/threadDump,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@70f646b8{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@16003b8f{/static,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@74d4cb1{/,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@58e40c1d{/api,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4f1a2aa7{/jobs/job/kill,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4420da38{/stages/stage/kill,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://iccluster056.iccluster.epfl.ch:40378
20/04/04 17:13:36 INFO YarnClusterScheduler: Created YarnClusterScheduler
20/04/04 17:13:36 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1580812675067_4186 and attemptId Some(appattempt_1580812675067_4186_000001)
20/04/04 17:13:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45435.
20/04/04 17:13:36 INFO NettyBlockTransferService: Server created on iccluster056.iccluster.epfl.ch:45435
20/04/04 17:13:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/04 17:13:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, iccluster056.iccluster.epfl.ch, 45435, None)
20/04/04 17:13:36 INFO BlockManagerMasterEndpoint: Registering block manager iccluster056.iccluster.epfl.ch:45435 with 366.3 MB RAM, BlockManagerId(driver, iccluster056.iccluster.epfl.ch, 45435, None)
20/04/04 17:13:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, iccluster056.iccluster.epfl.ch, 45435, None)
20/04/04 17:13:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, iccluster056.iccluster.epfl.ch, 45435, None)
20/04/04 17:13:36 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/04/04 17:13:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@49d69bcc{/metrics/json,null,AVAILABLE,@Spark}
20/04/04 17:13:36 INFO EventLoggingListener: Logging events to hdfs:/spark2-history/application_1580812675067_4186_1
20/04/04 17:13:37 INFO ApplicationMaster: 
===============================================================================
YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>$HADOOP_CONF_DIR<CPS>/usr/hdp/3.0.1.0-187/hadoop/*<CPS>/usr/hdp/3.0.1.0-187/hadoop/lib/*<CPS>/usr/hdp/current/hadoop-hdfs-client/*<CPS>/usr/hdp/current/hadoop-hdfs-client/lib/*<CPS>/usr/hdp/current/hadoop-yarn-client/*<CPS>/usr/hdp/current/hadoop-yarn-client/lib/*<CPS>$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:$PWD/mr-framework/hadoop/share/hadoop/tools/lib/*:/usr/hdp/3.0.1.0-187/hadoop/lib/hadoop-lzo-0.6.0.3.0.1.0-187.jar:/etc/hadoop/conf/secure<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_YARN_STAGING_DIR -> hdfs://iccluster040.iccluster.epfl.ch:8020/user/sahnoun/.sparkStaging/application_1580812675067_4186
    SPARK_USER -> sahnoun

  command:
    LD_LIBRARY_PATH="/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64:$LD_LIBRARY_PATH" \ 
      {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx1024m \ 
      '-XX:+UseNUMA' \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.history.ui.port=18081' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@iccluster056.iccluster.epfl.ch:40063 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      1 \ 
      --app-id \ 
      application_1580812675067_4186 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    __app__.jar -> resource { scheme: "hdfs" host: "iccluster040.iccluster.epfl.ch" port: 8020 file: "/user/sahnoun/.sparkStaging/application_1580812675067_4186/Milestone2_Group07.jar" } size: 68897 timestamp: 1586013212408 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "iccluster040.iccluster.epfl.ch" port: 8020 file: "/hdp/apps/3.0.1.0-187/spark2/spark2-hdp-yarn-archive.tar.gz" } size: 279537157 timestamp: 1580802651556 type: ARCHIVE visibility: PUBLIC
    __spark_conf__ -> resource { scheme: "hdfs" host: "iccluster040.iccluster.epfl.ch" port: 8020 file: "/user/sahnoun/.sparkStaging/application_1580812675067_4186/__spark_conf__.zip" } size: 277632 timestamp: 1586013212802 type: ARCHIVE visibility: PRIVATE
    __hive_libs__ -> resource { scheme: "hdfs" host: "iccluster040.iccluster.epfl.ch" port: 8020 file: "/hdp/apps/3.0.1.0-187/spark2/spark2-hdp-hive-archive.tar.gz" } size: 43606863 timestamp: 1580802654613 type: ARCHIVE visibility: PUBLIC

===============================================================================
20/04/04 17:13:37 INFO RMProxy: Connecting to ResourceManager at iccluster040.iccluster.epfl.ch/10.90.38.16:8030
20/04/04 17:13:37 INFO YarnRMClient: Registering the ApplicationMaster
20/04/04 17:13:37 INFO Configuration: found resource resource-types.xml at file:/etc/hadoop/3.0.1.0-187/0/resource-types.xml
20/04/04 17:13:37 INFO YarnAllocator: Will request 2 executor container(s), each with 1 core(s) and 1408 MB memory (including 384 MB of overhead)
20/04/04 17:13:37 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@iccluster056.iccluster.epfl.ch:40063)
20/04/04 17:13:37 INFO YarnAllocator: Submitted 2 unlocalized container requests.
20/04/04 17:13:37 INFO ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
20/04/04 17:13:37 INFO YarnAllocator: Launching container container_e02_1580812675067_4186_01_000002 on host iccluster063.iccluster.epfl.ch for executor with ID 1
20/04/04 17:13:37 INFO YarnAllocator: Launching container container_e02_1580812675067_4186_01_000003 on host iccluster055.iccluster.epfl.ch for executor with ID 2
20/04/04 17:13:37 INFO YarnAllocator: Received 2 containers from YARN, launching executors on 2 of them.
20/04/04 17:13:40 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.90.39.6:43920) with ID 2
20/04/04 17:13:40 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.90.39.14:42008) with ID 1
20/04/04 17:13:40 INFO BlockManagerMasterEndpoint: Registering block manager iccluster063.iccluster.epfl.ch:40402 with 408.9 MB RAM, BlockManagerId(1, iccluster063.iccluster.epfl.ch, 40402, None)
20/04/04 17:13:40 INFO YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
20/04/04 17:13:40 INFO YarnClusterScheduler: YarnClusterScheduler.postStartHook done
20/04/04 17:13:40 INFO BlockManagerMasterEndpoint: Registering block manager iccluster055.iccluster.epfl.ch:46685 with 408.9 MB RAM, BlockManagerId(2, iccluster055.iccluster.epfl.ch, 46685, None)
20/04/04 17:13:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 427.7 KB, free 365.9 MB)
20/04/04 17:13:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 43.7 KB, free 365.8 MB)
20/04/04 17:13:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on iccluster056.iccluster.epfl.ch:45435 (size: 43.7 KB, free: 366.3 MB)
20/04/04 17:13:40 INFO SparkContext: Created broadcast 0 from textFile at App3.scala:15
20/04/04 17:13:40 INFO FileInputFormat: Total input files to process : 1
20/04/04 17:13:41 INFO SparkContext: Starting job: collect at App3.scala:24
20/04/04 17:13:41 INFO DAGScheduler: Registering RDD 3 (groupBy at App3.scala:22)
20/04/04 17:13:41 INFO DAGScheduler: Got job 0 (collect at App3.scala:24) with 2 output partitions
20/04/04 17:13:41 INFO DAGScheduler: Final stage: ResultStage 1 (collect at App3.scala:24)
20/04/04 17:13:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
20/04/04 17:13:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
20/04/04 17:13:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at groupBy at App3.scala:22), which has no missing parents
20/04/04 17:13:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.2 KB, free 365.8 MB)
20/04/04 17:13:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.8 KB, free 365.8 MB)
20/04/04 17:13:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on iccluster056.iccluster.epfl.ch:45435 (size: 2.8 KB, free: 366.3 MB)
20/04/04 17:13:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
20/04/04 17:13:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at groupBy at App3.scala:22) (first 15 tasks are for partitions Vector(0, 1))
20/04/04 17:13:41 INFO YarnClusterScheduler: Adding task set 0.0 with 2 tasks
20/04/04 17:13:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, iccluster063.iccluster.epfl.ch, executor 1, partition 0, NODE_LOCAL, 7889 bytes)
20/04/04 17:13:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on iccluster063.iccluster.epfl.ch:40402 (size: 2.8 KB, free: 408.9 MB)
20/04/04 17:13:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on iccluster063.iccluster.epfl.ch:40402 (size: 43.7 KB, free: 408.9 MB)
20/04/04 17:13:44 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, iccluster055.iccluster.epfl.ch, executor 2, partition 1, RACK_LOCAL, 7889 bytes)
20/04/04 17:13:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on iccluster055.iccluster.epfl.ch:46685 (size: 2.8 KB, free: 408.9 MB)
20/04/04 17:13:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on iccluster055.iccluster.epfl.ch:46685 (size: 43.7 KB, free: 408.9 MB)
20/04/04 17:13:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8522 ms on iccluster063.iccluster.epfl.ch (executor 1) (1/2)
20/04/04 17:13:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 7988 ms on iccluster055.iccluster.epfl.ch (executor 2) (2/2)
20/04/04 17:13:52 INFO YarnClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/04/04 17:13:52 INFO DAGScheduler: ShuffleMapStage 0 (groupBy at App3.scala:22) finished in 11.363 s
20/04/04 17:13:52 INFO DAGScheduler: looking for newly runnable stages
20/04/04 17:13:52 INFO DAGScheduler: running: Set()
20/04/04 17:13:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
20/04/04 17:13:52 INFO DAGScheduler: failed: Set()
20/04/04 17:13:52 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at flatMap at App3.scala:23), which has no missing parents
20/04/04 17:13:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.4 KB, free 365.8 MB)
20/04/04 17:13:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.2 KB, free 365.8 MB)
20/04/04 17:13:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on iccluster056.iccluster.epfl.ch:45435 (size: 3.2 KB, free: 366.3 MB)
20/04/04 17:13:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
20/04/04 17:13:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at flatMap at App3.scala:23) (first 15 tasks are for partitions Vector(0, 1))
20/04/04 17:13:52 INFO YarnClusterScheduler: Adding task set 1.0 with 2 tasks
20/04/04 17:13:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, iccluster063.iccluster.epfl.ch, executor 1, partition 0, NODE_LOCAL, 7638 bytes)
20/04/04 17:13:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, iccluster055.iccluster.epfl.ch, executor 2, partition 1, NODE_LOCAL, 7638 bytes)
20/04/04 17:13:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on iccluster063.iccluster.epfl.ch:40402 (size: 3.2 KB, free: 408.9 MB)
20/04/04 17:13:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on iccluster055.iccluster.epfl.ch:46685 (size: 3.2 KB, free: 408.9 MB)
20/04/04 17:13:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.90.39.14:42008
20/04/04 17:13:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.90.39.6:43920
20/04/04 17:15:31 INFO YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 2.
20/04/04 17:15:31 INFO DAGScheduler: Executor lost: 2 (epoch 1)
20/04/04 17:15:31 INFO BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
20/04/04 17:15:31 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, iccluster055.iccluster.epfl.ch, 46685, None)
20/04/04 17:15:31 INFO BlockManagerMaster: Removed 2 successfully in removeExecutor
20/04/04 17:15:31 INFO DAGScheduler: Shuffle files lost for executor: 2 (epoch 1)
20/04/04 17:15:32 INFO YarnAllocator: Completed container container_e02_1580812675067_4186_01_000003 on host: iccluster055.iccluster.epfl.ch (state: COMPLETE, exit status: 143)
20/04/04 17:15:32 WARN YarnAllocator: Container marked as failed: container_e02_1580812675067_4186_01_000003 on host: iccluster055.iccluster.epfl.ch. Exit status: 143. Diagnostics: [2020-04-04 17:15:31.846]Container killed on request. Exit code is 143
[2020-04-04 17:15:31.846]Container exited with a non-zero exit code 143. 
[2020-04-04 17:15:31.849]Killed by external signal

20/04/04 17:15:32 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container marked as failed: container_e02_1580812675067_4186_01_000003 on host: iccluster055.iccluster.epfl.ch. Exit status: 143. Diagnostics: [2020-04-04 17:15:31.846]Container killed on request. Exit code is 143
[2020-04-04 17:15:31.846]Container exited with a non-zero exit code 143. 
[2020-04-04 17:15:31.849]Killed by external signal

20/04/04 17:15:32 ERROR YarnClusterScheduler: Lost executor 2 on iccluster055.iccluster.epfl.ch: Container marked as failed: container_e02_1580812675067_4186_01_000003 on host: iccluster055.iccluster.epfl.ch. Exit status: 143. Diagnostics: [2020-04-04 17:15:31.846]Container killed on request. Exit code is 143
[2020-04-04 17:15:31.846]Container exited with a non-zero exit code 143. 
[2020-04-04 17:15:31.849]Killed by external signal

20/04/04 17:15:32 WARN TaskSetManager: Lost task 1.0 in stage 1.0 (TID 3, iccluster055.iccluster.epfl.ch, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_e02_1580812675067_4186_01_000003 on host: iccluster055.iccluster.epfl.ch. Exit status: 143. Diagnostics: [2020-04-04 17:15:31.846]Container killed on request. Exit code is 143
[2020-04-04 17:15:31.846]Container exited with a non-zero exit code 143. 
[2020-04-04 17:15:31.849]Killed by external signal

20/04/04 17:15:32 ERROR TaskSetManager: Task 1 in stage 1.0 failed 1 times; aborting job
20/04/04 17:15:32 INFO BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
20/04/04 17:15:32 INFO BlockManagerMaster: Removal of executor 2 requested
20/04/04 17:15:32 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 2
20/04/04 17:15:32 INFO YarnClusterScheduler: Cancelling stage 1
20/04/04 17:15:32 INFO YarnClusterScheduler: Stage 1 was cancelled
20/04/04 17:15:32 INFO DAGScheduler: ResultStage 1 (collect at App3.scala:24) failed in 99.625 s due to Job aborted due to stage failure: Task 1 in stage 1.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1.0 (TID 3, iccluster055.iccluster.epfl.ch, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_e02_1580812675067_4186_01_000003 on host: iccluster055.iccluster.epfl.ch. Exit status: 143. Diagnostics: [2020-04-04 17:15:31.846]Container killed on request. Exit code is 143
[2020-04-04 17:15:31.846]Container exited with a non-zero exit code 143. 
[2020-04-04 17:15:31.849]Killed by external signal

Driver stacktrace:
20/04/04 17:15:32 INFO DAGScheduler: Job 0 failed: collect at App3.scala:24, took 111.082389 s
20/04/04 17:15:32 ERROR ApplicationMaster: User class threw exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1.0 (TID 3, iccluster055.iccluster.epfl.ch, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_e02_1580812675067_4186_01_000003 on host: iccluster055.iccluster.epfl.ch. Exit status: 143. Diagnostics: [2020-04-04 17:15:31.846]Container killed on request. Exit code is 143
[2020-04-04 17:15:31.846]Container exited with a non-zero exit code 143. 
[2020-04-04 17:15:31.849]Killed by external signal

Driver stacktrace:
org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1.0 (TID 3, iccluster055.iccluster.epfl.ch, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_e02_1580812675067_4186_01_000003 on host: iccluster055.iccluster.epfl.ch. Exit status: 143. Diagnostics: [2020-04-04 17:15:31.846]Container killed on request. Exit code is 143
[2020-04-04 17:15:31.846]Container exited with a non-zero exit code 143. 
[2020-04-04 17:15:31.849]Killed by external signal

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1609)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1597)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1596)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1596)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1830)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1779)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1768)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:938)
	at App3$.main(App3.scala:24)
	at App3.main(App3.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721)
20/04/04 17:15:32 INFO ApplicationMaster: Final app status: FAILED, exitCode: 15, (reason: User class threw exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1.0 (TID 3, iccluster055.iccluster.epfl.ch, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_e02_1580812675067_4186_01_000003 on host: iccluster055.iccluster.epfl.ch. Exit status: 143. Diagnostics: [2020-04-04 17:15:31.846]Container killed on request. Exit code is 143
[2020-04-04 17:15:31.846]Container exited with a non-zero exit code 143. 
[2020-04-04 17:15:31.849]Killed by external signal

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1609)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1597)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1596)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1596)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1830)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1779)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1768)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:938)
	at App3$.main(App3.scala:24)
	at App3.main(App3.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721)
)
20/04/04 17:15:32 INFO SparkContext: Invoking stop() from shutdown hook
20/04/04 17:15:32 INFO AbstractConnector: Stopped Spark@3a999908{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
20/04/04 17:15:32 INFO SparkUI: Stopped Spark web UI at http://iccluster056.iccluster.epfl.ch:40378
20/04/04 17:15:32 INFO YarnAllocator: Driver requested a total number of 0 executor(s).
20/04/04 17:15:32 INFO YarnClusterSchedulerBackend: Shutting down all executors
20/04/04 17:15:32 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/04/04 17:15:32 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
20/04/04 17:15:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/04/04 17:15:32 INFO MemoryStore: MemoryStore cleared
20/04/04 17:15:32 INFO BlockManager: BlockManager stopped
20/04/04 17:15:32 INFO BlockManagerMaster: BlockManagerMaster stopped
20/04/04 17:15:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/04/04 17:15:32 INFO SparkContext: Successfully stopped SparkContext
20/04/04 17:15:32 INFO ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: User class threw exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1.0 (TID 3, iccluster055.iccluster.epfl.ch, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_e02_1580812675067_4186_01_000003 on host: iccluster055.iccluster.epfl.ch. Exit status: 143. Diagnostics: [2020-04-04 17:15:31.846]Container killed on request. Exit code is 143
[2020-04-04 17:15:31.846]Container exited with a non-zero exit code 143. 
[2020-04-04 17:15:31.849]Killed by external signal

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1609)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1597)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1596)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1596)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1830)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1779)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1768)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:938)
	at App3$.main(App3.scala:24)
	at App3.main(App3.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721)
)
20/04/04 17:15:32 INFO AMRMClientImpl: Waiting for application to be successfully unregistered.
20/04/04 17:15:32 INFO ApplicationMaster: Deleting staging directory hdfs://iccluster040.iccluster.epfl.ch:8020/user/sahnoun/.sparkStaging/application_1580812675067_4186
20/04/04 17:15:32 INFO ShutdownHookManager: Shutdown hook called
20/04/04 17:15:32 INFO ShutdownHookManager: Deleting directory /hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/spark-32f9f354-3e32-41b3-8641-4c8ff8a843b9
20/04/04 17:15:32 INFO ShutdownHookManager: Deleting directory /hdata/sdf/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/spark-465e5e8c-9db7-4845-9e8b-3994a5d2e92a
20/04/04 17:15:32 INFO ShutdownHookManager: Deleting directory /hdata/sdc/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/spark-b04aca5a-9c51-478b-8482-2ff69d78f4f9
20/04/04 17:15:32 INFO ShutdownHookManager: Deleting directory /hdata/sdg/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/spark-b898135c-decf-4622-ba6a-fb311912b78d
20/04/04 17:15:32 INFO ShutdownHookManager: Deleting directory /hdata/sde/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/spark-41e11e97-19d2-4ebe-8794-9cb42d462f3d
20/04/04 17:15:32 INFO ShutdownHookManager: Deleting directory /hdata/sdb/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/spark-1f31dcf5-2481-419f-ac32-31492ec9c9db
20/04/04 17:15:32 INFO ShutdownHookManager: Deleting directory /hdata/sdd/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/spark-c274a364-88ae-4279-a109-8d96041114f5

End of LogType:stderr
***********************************************************************

Container: container_e02_1580812675067_4186_01_000002 on iccluster063.iccluster.epfl.ch_45454_1586013334221
LogAggregationType: AGGREGATED
===========================================================================================================
LogType:stderr
LogLastModifiedTime:Sat Apr 04 17:15:34 +0200 2020
LogLength:7542
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/hdata/sdd/hadoop/yarn/local/filecache/11/spark2-hdp-yarn-archive.tar.gz/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.0.1.0-187/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/04/04 17:13:38 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 8076@iccluster063
20/04/04 17:13:38 INFO SignalUtils: Registered signal handler for TERM
20/04/04 17:13:38 INFO SignalUtils: Registered signal handler for HUP
20/04/04 17:13:38 INFO SignalUtils: Registered signal handler for INT
20/04/04 17:13:39 INFO SecurityManager: Changing view acls to: yarn,sahnoun
20/04/04 17:13:39 INFO SecurityManager: Changing modify acls to: yarn,sahnoun
20/04/04 17:13:39 INFO SecurityManager: Changing view acls groups to: 
20/04/04 17:13:39 INFO SecurityManager: Changing modify acls groups to: 
20/04/04 17:13:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, sahnoun); groups with view permissions: Set(); users  with modify permissions: Set(yarn, sahnoun); groups with modify permissions: Set()
20/04/04 17:13:39 INFO TransportClientFactory: Successfully created connection to iccluster056.iccluster.epfl.ch/10.90.39.7:40063 after 83 ms (0 ms spent in bootstraps)
20/04/04 17:13:39 INFO SecurityManager: Changing view acls to: yarn,sahnoun
20/04/04 17:13:39 INFO SecurityManager: Changing modify acls to: yarn,sahnoun
20/04/04 17:13:39 INFO SecurityManager: Changing view acls groups to: 
20/04/04 17:13:39 INFO SecurityManager: Changing modify acls groups to: 
20/04/04 17:13:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, sahnoun); groups with view permissions: Set(); users  with modify permissions: Set(yarn, sahnoun); groups with modify permissions: Set()
20/04/04 17:13:39 INFO TransportClientFactory: Successfully created connection to iccluster056.iccluster.epfl.ch/10.90.39.7:40063 after 1 ms (0 ms spent in bootstraps)
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-c0c5a38e-a7c8-49bb-b773-207221730d9e
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sdb/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-5e03a49f-3878-4874-8372-01f01faef70e
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sdc/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-70b87b59-fbef-4ff7-aa97-949ca8e34f3b
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sdd/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-48a3e5d6-8f56-4aa6-810f-1ca00027fdf5
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sde/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-876e0112-f9bb-4e2e-a8d3-178cb022304c
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sdf/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-69378557-020f-4d9e-b7be-263ce5cc73f3
20/04/04 17:13:39 INFO DiskBlockManager: Created local directory at /hdata/sdg/hadoop/yarn/local/usercache/sahnoun/appcache/application_1580812675067_4186/blockmgr-eb1a900d-adf4-411c-826f-0c5c17b933c4
20/04/04 17:13:39 INFO MemoryStore: MemoryStore started with capacity 408.9 MB
20/04/04 17:13:40 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@iccluster056.iccluster.epfl.ch:40063
20/04/04 17:13:40 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
20/04/04 17:13:40 INFO Executor: Starting executor ID 1 on host iccluster063.iccluster.epfl.ch
20/04/04 17:13:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40402.
20/04/04 17:13:40 INFO NettyBlockTransferService: Server created on iccluster063.iccluster.epfl.ch:40402
20/04/04 17:13:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/04/04 17:13:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(1, iccluster063.iccluster.epfl.ch, 40402, None)
20/04/04 17:13:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(1, iccluster063.iccluster.epfl.ch, 40402, None)
20/04/04 17:13:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(1, iccluster063.iccluster.epfl.ch, 40402, None)
20/04/04 17:13:41 INFO CoarseGrainedExecutorBackend: Got assigned task 0
20/04/04 17:13:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/04/04 17:13:41 INFO TorrentBroadcast: Started reading broadcast variable 1
20/04/04 17:13:41 INFO TransportClientFactory: Successfully created connection to iccluster056.iccluster.epfl.ch/10.90.39.7:45435 after 1 ms (0 ms spent in bootstraps)
20/04/04 17:13:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.8 KB, free 408.9 MB)
20/04/04 17:13:41 INFO TorrentBroadcast: Reading broadcast variable 1 took 142 ms
20/04/04 17:13:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.2 KB, free 408.9 MB)
20/04/04 17:13:41 INFO HadoopRDD: Input split: hdfs://iccluster040.iccluster.epfl.ch:8020/cs449/data1_large.csv:0+53999515
20/04/04 17:13:41 INFO TorrentBroadcast: Started reading broadcast variable 0
20/04/04 17:13:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 43.7 KB, free 408.8 MB)
20/04/04 17:13:41 INFO TorrentBroadcast: Reading broadcast variable 0 took 14 ms
20/04/04 17:13:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 673.8 KB, free 408.2 MB)
20/04/04 17:13:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1081 bytes result sent to driver
20/04/04 17:13:52 INFO CoarseGrainedExecutorBackend: Got assigned task 2
20/04/04 17:13:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
20/04/04 17:13:52 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
20/04/04 17:13:52 INFO TorrentBroadcast: Started reading broadcast variable 2
20/04/04 17:13:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.2 KB, free 408.2 MB)
20/04/04 17:13:52 INFO TorrentBroadcast: Reading broadcast variable 2 took 14 ms
20/04/04 17:13:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.4 KB, free 408.2 MB)
20/04/04 17:13:52 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
20/04/04 17:13:52 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@iccluster056.iccluster.epfl.ch:40063)
20/04/04 17:13:52 INFO MapOutputTrackerWorker: Got the output locations
20/04/04 17:13:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
20/04/04 17:13:52 INFO TransportClientFactory: Successfully created connection to iccluster055.iccluster.epfl.ch/10.90.39.6:46685 after 1 ms (0 ms spent in bootstraps)
20/04/04 17:13:52 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 11 ms

End of LogType:stderr
***********************************************************************

